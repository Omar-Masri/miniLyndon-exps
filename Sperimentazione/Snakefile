ML_PRESETS = {
    "min5": "-k 5 -w 11",
    "min7": "-k 7 -w 13",
}

MINIMAP_PRESETS = {
    "ONT": "-x ava-ont",
    "PB": "-x ava-pb",
}

READ_DATASETS = expand(
    "Ecoli_K12_DH10B/{reads}", reads=["Ecoli10", "Ecoli25", "Ecoli50", "Ecoli100"]
) + expand(
    "Celegans_UNSB01/Celegans_UNSB01.{type}.{cov}",
    type=["perfect", "ccs"],
    cov=[10, 25, 50],
)

TARGETS = (
    expand(
        "Results/{dataset}/minimap2/{tp}/quast",
        dataset=READ_DATASETS,
        tp=MINIMAP_PRESETS.keys(),
    )
    + expand(
        "Results/{dataset}/miniLyndon/{preset}|CFL_ICFL|{comb}|{segment_size}/quast",
        dataset=READ_DATASETS,
        preset=ML_PRESETS.keys(),
        comb=["NONCOMB", "COMB"],
        segment_size=[
            100,
            300,
            500,
        ],  # Removed -1 since it is not able to find (enough) overlaps w/o cutting the read
    )
    + expand(
        "Results/{dataset}/miniLyndon/{preset}|CFL_ICFL_R|{comb}|{recursive_size}/quast",
        dataset=READ_DATASETS,
        preset=ML_PRESETS.keys(),
        comb=["NONCOMB", "COMB"],
        recursive_size=[10, 25, 50],
    )
)


rule run:
    input:
        TARGETS,


rule multiqc:
    input:
        targets=TARGETS,
    output:
        directory("multiqc_report"),
    conda:
        "envs/multiqc.yml"
    shell:
        """multiqc -o "{output}" -dd 5 --force {input.targets:q}"""


rule gunzip_ref_genome:
    input:
        "Genomes/{genome}.fa.gz",
    output:
        temp("Genomes/{genome}.fa"),
    shell:
        "gunzip -k {input}"


rule download_celegans_genome:
    output:
        genome="Genomes/Celegans_UNSB01.fa.gz",
    params:
        url="https://ftp.ebi.ac.uk/pub/databases/ena/wgs/public/uns/UNSB01.fasta.gz",
    log:
        "Genomes/Celegans_UNSB01.wget.log",
    shell:
        "wget -O {output.genome} -o {log} {params.url}"


rule simulate_reads:
    input:
        genome="Genomes/{genome}.fasta.gz",
    output:
        prefix=directory("Reads/{genome}/depth_{depth}"),
        bam="Reads/{genome}/depth_{depth}/reads.bam",
        maf="Reads/{genome}/depth_{depth}/reads.maf.gz",
    log:
        pbsim="Reads/{genome}/depth_{depth}/pbsim.log",
        samtools="Reads/{genome}/depth_{depth}/samtools.log",
    params:
        seed=250323,
        lmean=20700,
        lsd=2500,
        passnum=20,
        prefix=lambda wildcards, output: output[0] + "/S",
    conda:
        "envs/pbsim3.yml"
    shell:
        """
        pbsim --strategy wgs --method qshmm --qshmm ${{CONDA_PREFIX}}/data/QSHMM-RSII.model --genome <( zcat -f {input.genome} ) --depth {wildcards.depth} --pass-num {params.passnum} --seed {params.seed} --length-mean {params.lmean} --length-sd {params.lsd} --prefix {params.prefix} 2> {log.pbsim};
        cat {params.prefix}_*.maf.gz > {output.maf};
        samtools cat -o {output.bam} {params.prefix}_*.bam 2> {log.samtools};
        rm -f {params.prefix}_*.maf.gz {params.prefix}_*.bam {params.prefix}_*.ref
        """


rule extract_perfect_reads:
    input:
        maf="Reads/{genome}/depth_{depth}/reads.maf.gz",
    output:
        reads="Reads/{genome}.perfect.{depth}.fa",
    shell:
        """
        zcat {input.maf} | awk -f scripts/maf2fa.awk > {output.reads}
        """


rule simulate_ccs_reads:
    input:
        bam="Reads/{genome}/depth_{depth}/reads.bam",
    output:
        reads="Reads/{genome}.ccs.{depth}.fq.gz",
    log:
        ccs="Reads/{genome}.ccs.{depth}.log",
    conda:
        "envs/pbsim3.yml"
    threads: 8
    shell:
        """
        ccs --all --log-level INFO -j {threads} {input.bam} {output.reads} 2> {log.ccs}
        """


rule fq2fa:
    input:
        fq="Reads/{read}.fq.gz",
    output:
        fa="Reads/{read}.fa",
    shell:
        """
        zcat {input.fq} | awk '(NR % 4 == 1) {{ print }} (NR % 4 == 2) {{ print }}' | sed 's/^@/>/' > {output.fa}
        """


rule miniLyndon:
    input:
        fa="Reads/{read}.fa",
    output:
        paf="Results/{reference}/{read}/miniLyndon/{preset}|{factorization}|{comb}|{size}.paf",
    log:
        "Results/{reference}/{read}/miniLyndon/{preset}|{factorization}|{comb}|{size}.log",
    benchmark:
        "Results/{reference}/{read}/miniLyndon/{preset}|{factorization}|{comb}|{size}.tsv"
    params:
        segment_recursive_size=lambda wildcards: (
            "-s " + wildcards.size
            if wildcards.factorization == "CFL_ICFL"
            else "-r " + wildcards.size
        ),
        comb_value=lambda wildcards: 1 if wildcards.comb == "COMB" else 0,
        preset_params=lambda wildcards: ML_PRESETS[wildcards.preset],
        prefix=lambda wildcards, input: subpath(input.fa, parent=True) + "/",
        read_file_name=lambda wildcards, input: subpath(input.fa, basename=True),
    threads: 4
    shell:
        """
        {{ ../miniLyndon/bin/fingerprint -f "{wildcards.factorization}" -p "{params.prefix}" -a "{params.read_file_name}" -n {threads} {params.segment_recursive_size} -c {params.comb_value} | \
        ../miniLyndon/bin/minimizer_demo -t {threads} {params.preset_params} | \
        ../miniLyndon/bin/postprocessing "{input.fa}" > "{output.paf}" ; }} &> "{log}"
        """


rule minimap:
    input:
        "Reads/{read}.fa",
    output:
        paf="Results/{reference}/{read}/minimap2/{tp}.paf",
    log:
        "Results/{reference}/{read}/minimap2/{tp}.log",
    benchmark:
        "Results/{reference}/{read}/minimap2/{tp}.tsv"
    params:
        read_type=lambda wildcards: MINIMAP_PRESETS[wildcards.tp],
    threads: 4
    conda:
        "envs/minimap2.yml"
    shell:
        """
        minimap2 {params.read_type} -t {threads} "{input}" "{input}" > "{output.paf}" 2> "{log}"
        """


rule miniasm:
    input:
        read="Reads/{read}.fa",
        paf="Results/{reference}/{read}/{tool}/{conf}.paf",
    output:
        gfa="Results/{reference}/{read}/{tool}/{conf}/miniasm_graph.gfa",
        fa="Results/{reference}/{read}/{tool}/{conf}/miniasm_asm.fa",
    log:
        "Results/{reference}/{read}/{tool}/{conf}/miniasm.log",
    threads: 1
    conda:
        "envs/miniasm.yml"
    shell:
        """
        miniasm -f "{input.read}" "{input.paf}" > "{output.gfa}" 2> "{log}" &&
        awk '/^S/{{print \">\" $2 \"\\n\" $3}}' "{output.gfa}" | fold > "{output.fa}"
        """


rule quast:
    input:
        genome="Genomes/{reference}.fa",
        fa="Results/{reference}/{read}/{tool}/{conf}/miniasm_asm.fa",
    output:
        folder=directory("Results/{reference}/{read}/{tool}/{conf}/quast"),
    log:
        "Results/{reference}/{read}/{tool}/{conf}/quast.log",
    threads: 1
    conda:
        "envs/quast.yml"
    shell:
        """
        quast --threads {threads} "{input.fa}" -r "{input.genome}" -o "{output.folder}" &> "{log}"
        """


# rule clean:
#     shell:
#         """
#         rm -f -r Results
#         rm -f -r ./miniasm/*
#         """
#
#
# snakemake --sdm conda --cores 8
# snakemake --sdm conda --cores 8 -f multiqc
